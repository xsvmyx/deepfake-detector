{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class DeepfakeDetectorCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepfakeDetectorCNN, self).__init__()\n",
    "        \n",
    "        # Layer 1 :256x256 -> 128x128 \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Layer 2 : 64x64\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Layer 3 : 32x32\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Layer 4 :  16x16\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # Layer 5 :  8x8\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully Connected layers\n",
    "        # 512 filtres * 8 * 8 pixels restants\n",
    "        self.fc1 = nn.Linear(512 * 8 * 8, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 1) # Sortie binaire (Fake ou Real)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "        \n",
    "        x = x.view(-1, 512 * 8 * 8) # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f724e612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  True\n",
      "GPU name:  NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Training on device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"GPU name: \", torch.cuda.get_device_name(0))\n",
    "print(f\"Training on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eea24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "model = DeepfakeDetectorCNN().to(device)\n",
    "\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4) \n",
    "\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcfa340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  47991\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"../images/train\", transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(\"../images/val\", transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "print(\"Number of training samples: \", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6965d55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 1500/1500 [02:59<00:00,  8.37it/s, Loss=0.4162, Acc=74.70%]\n",
      "Epoch 1/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1 Summary ---\n",
      "Train Acc: 74.70% | Val Acc: 78.86% | Val Loss: 0.4541\n",
      "Metrics (Fake Class 0) -> Precision: 0.7645 | Recall: 0.8343 | F1: 0.7979\n",
      "⭐ New F1-Score record: 0.7979! Model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Train]: 100%|██████████| 1500/1500 [03:00<00:00,  8.31it/s, Loss=0.3738, Acc=78.05%]\n",
      "Epoch 2/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 2 Summary ---\n",
      "Train Acc: 78.05% | Val Acc: 80.43% | Val Loss: 0.4274\n",
      "Metrics (Fake Class 0) -> Precision: 0.7827 | Recall: 0.8427 | F1: 0.8116\n",
      "⭐ New F1-Score record: 0.8116! Model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Train]: 100%|██████████| 1500/1500 [03:00<00:00,  8.30it/s, Loss=0.3157, Acc=79.56%]\n",
      "Epoch 3/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 3 Summary ---\n",
      "Train Acc: 79.56% | Val Acc: 82.04% | Val Loss: 0.3978\n",
      "Metrics (Fake Class 0) -> Precision: 0.8042 | Recall: 0.8473 | F1: 0.8252\n",
      "⭐ New F1-Score record: 0.8252! Model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.29it/s, Loss=0.1848, Acc=80.70%]\n",
      "Epoch 4/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 4 Summary ---\n",
      "Train Acc: 80.70% | Val Acc: 82.11% | Val Loss: 0.3953\n",
      "Metrics (Fake Class 0) -> Precision: 0.8093 | Recall: 0.8403 | F1: 0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Train]: 100%|██████████| 1500/1500 [03:00<00:00,  8.29it/s, Loss=0.5640, Acc=81.44%]\n",
      "Epoch 5/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 5 Summary ---\n",
      "Train Acc: 81.44% | Val Acc: 83.18% | Val Loss: 0.3777\n",
      "Metrics (Fake Class 0) -> Precision: 0.8177 | Recall: 0.8540 | F1: 0.8355\n",
      "⭐ New F1-Score record: 0.8355! Model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.28it/s, Loss=0.4208, Acc=82.24%]\n",
      "Epoch 6/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 6 Summary ---\n",
      "Train Acc: 82.24% | Val Acc: 82.98% | Val Loss: 0.3800\n",
      "Metrics (Fake Class 0) -> Precision: 0.8696 | Recall: 0.7760 | F1: 0.8202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.29it/s, Loss=0.2463, Acc=82.68%]\n",
      "Epoch 7/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 7 Summary ---\n",
      "Train Acc: 82.68% | Val Acc: 80.99% | Val Loss: 0.4240\n",
      "Metrics (Fake Class 0) -> Precision: 0.7468 | Recall: 0.9380 | F1: 0.8316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.28it/s, Loss=0.3562, Acc=83.42%]\n",
      "Epoch 8/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 8 Summary ---\n",
      "Train Acc: 83.42% | Val Acc: 86.00% | Val Loss: 0.3289\n",
      "Metrics (Fake Class 0) -> Precision: 0.8569 | Recall: 0.8643 | F1: 0.8606\n",
      "⭐ New F1-Score record: 0.8606! Model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.29it/s, Loss=0.2482, Acc=83.82%]\n",
      "Epoch 9/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 9 Summary ---\n",
      "Train Acc: 83.82% | Val Acc: 84.41% | Val Loss: 0.3462\n",
      "Metrics (Fake Class 0) -> Precision: 0.8036 | Recall: 0.9110 | F1: 0.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.28it/s, Loss=0.2987, Acc=84.30%]\n",
      "Epoch 10/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 10 Summary ---\n",
      "Train Acc: 84.30% | Val Acc: 85.46% | Val Loss: 0.3259\n",
      "Metrics (Fake Class 0) -> Precision: 0.8304 | Recall: 0.8913 | F1: 0.8598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.28it/s, Loss=0.3078, Acc=84.94%]\n",
      "Epoch 11/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 11 Summary ---\n",
      "Train Acc: 84.94% | Val Acc: 84.76% | Val Loss: 0.3512\n",
      "Metrics (Fake Class 0) -> Precision: 0.9185 | Recall: 0.7630 | F1: 0.8336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.26it/s, Loss=0.3725, Acc=85.23%]\n",
      "Epoch 12/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 12 Summary ---\n",
      "Train Acc: 85.23% | Val Acc: 87.38% | Val Loss: 0.3018\n",
      "Metrics (Fake Class 0) -> Precision: 0.8700 | Recall: 0.8790 | F1: 0.8745\n",
      "⭐ New F1-Score record: 0.8745! Model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.27it/s, Loss=0.2858, Acc=85.46%]\n",
      "Epoch 13/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 13 Summary ---\n",
      "Train Acc: 85.46% | Val Acc: 87.51% | Val Loss: 0.3008\n",
      "Metrics (Fake Class 0) -> Precision: 0.8793 | Recall: 0.8697 | F1: 0.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.28it/s, Loss=0.2931, Acc=85.72%]\n",
      "Epoch 14/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 14 Summary ---\n",
      "Train Acc: 85.72% | Val Acc: 86.36% | Val Loss: 0.3139\n",
      "Metrics (Fake Class 0) -> Precision: 0.8793 | Recall: 0.8430 | F1: 0.8608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.28it/s, Loss=0.1934, Acc=86.22%]\n",
      "Epoch 15/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 15 Summary ---\n",
      "Train Acc: 86.22% | Val Acc: 85.86% | Val Loss: 0.3263\n",
      "Metrics (Fake Class 0) -> Precision: 0.9148 | Recall: 0.7910 | F1: 0.8484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.27it/s, Loss=0.7041, Acc=86.29%]\n",
      "Epoch 16/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 16 Summary ---\n",
      "Train Acc: 86.29% | Val Acc: 82.93% | Val Loss: 0.3907\n",
      "Metrics (Fake Class 0) -> Precision: 0.8386 | Recall: 0.8157 | F1: 0.8270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.28it/s, Loss=0.2206, Acc=88.45%]\n",
      "Epoch 17/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 17 Summary ---\n",
      "Train Acc: 88.45% | Val Acc: 88.98% | Val Loss: 0.2645\n",
      "Metrics (Fake Class 0) -> Precision: 0.8985 | Recall: 0.8790 | F1: 0.8886\n",
      "⭐ New F1-Score record: 0.8886! Model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.27it/s, Loss=0.3514, Acc=88.74%]\n",
      "Epoch 18/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 18 Summary ---\n",
      "Train Acc: 88.74% | Val Acc: 88.91% | Val Loss: 0.2628\n",
      "Metrics (Fake Class 0) -> Precision: 0.8852 | Recall: 0.8943 | F1: 0.8897\n",
      "⭐ New F1-Score record: 0.8897! Model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.28it/s, Loss=0.5376, Acc=89.02%]\n",
      "Epoch 19/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 22.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 19 Summary ---\n",
      "Train Acc: 89.02% | Val Acc: 88.91% | Val Loss: 0.2645\n",
      "Metrics (Fake Class 0) -> Precision: 0.9084 | Recall: 0.8657 | F1: 0.8865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Train]: 100%|██████████| 1500/1500 [03:01<00:00,  8.25it/s, Loss=0.3097, Acc=89.18%]\n",
      "Epoch 20/20 [Val]: 100%|██████████| 188/188 [00:08<00:00, 21.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 20 Summary ---\n",
      "Train Acc: 89.18% | Val Acc: 88.85% | Val Loss: 0.2601\n",
      "Metrics (Fake Class 0) -> Precision: 0.9004 | Recall: 0.8737 | F1: 0.8868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "num_epochs = 20\n",
    "best_f1 = 0.0\n",
    "\n",
    "print(f\"Starting training on {device}...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ================= TRAIN PHASE =================\n",
    "    model.train()\n",
    "    correct, total, running_loss = 0, 0, 0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "\n",
    "    for images, labels in train_bar:\n",
    "        images = images.to(device)\n",
    "        # Reshape labels to (batch_size, 1) and convert to float for BCELoss\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Predictions: if output > 0.5 then 1 (Real), else 0 (Fake)\n",
    "        preds = (outputs > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_bar.set_postfix({\n",
    "            \"Loss\": f\"{loss.item():.4f}\", \n",
    "            \"Acc\": f\"{100*correct/total:.2f}%\"\n",
    "        })\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    # ================= VALIDATION PHASE =================\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        for images, labels in val_bar:\n",
    "            images = images.to(device)\n",
    "            labels_float = labels.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels_float)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Binary classification threshold\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy()) # Keep original labels for metrics\n",
    "\n",
    "    # Calculate Metrics\n",
    "    # Pos_label=0 because we focus on detecting \"Fake\"\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, np.array(all_preds).flatten(), average='binary', pos_label=0\n",
    "    )\n",
    "    \n",
    "    val_acc = 100 * np.sum(np.array(all_preds).flatten() == np.array(all_labels)) / len(all_labels)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # Adaptive Learning Rate Update\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"\\n--- Epoch {epoch+1} Summary ---\")\n",
    "    print(f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}% | Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Metrics (Fake Class 0) -> Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "    # ================= CHECKPOINT =================\n",
    "    if f1 > best_f1: \n",
    "        best_f1 = f1\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"f1_score\": f1,\n",
    "            \"val_loss\": avg_val_loss\n",
    "        }, \"best_deepfake_detector.pt\")\n",
    "        print(f\"⭐ New F1-Score record: {f1:.4f}! Model saved.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
